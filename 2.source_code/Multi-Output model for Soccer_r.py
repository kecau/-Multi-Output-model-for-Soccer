# -*- coding: utf-8 -*-
"""football_211206_for review_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12wVdv0_-cM4yZR_4WO4GzXvG5EvwbRKl
"""

import math
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental.preprocessing import StringLookup
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix
from numpy import argmax
import itertools

!git clone https://github.com/kecau/Multi-Output-model-for-Soccer.git

dataframe = pd.read_excel('/content/Multi-Output-model-for-Soccer/1_Data/Data.xlsx',  sheet_name = ['20-21','19-20', '18-19', '17-18', '16-17', '15-16', '14-15', '13-14', '12-13', '11-12', '10-11'])
dataframe = pd.concat(dataframe, axis= 0, ignore_index=True)

dataframe.columns

CSV_HEADER = ["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Opp_Level', 'Season','Ball_pos','match_oder', 'oppense_team', 'Formation', 'Win', 'Style','sum']


CATEGORICAL_DATA = ['match_oder', 'oppense_team','Opp_Level', 'Season' ]


CATEGORICAL_FEATURES_WITH_VOCABULARY = {
    feature_name: sorted([str(value) for value in list(dataframe[feature_name].unique())])
    for feature_name in CSV_HEADER
    if feature_name
    in list(CATEGORICAL_DATA)
}

NUMERIC_FEATURE_NAMES = ['Ball_pos']
BINARY_FEATURE_NAMES = ["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1']



FEATURE_NAMES = NUMERIC_FEATURE_NAMES + BINARY_FEATURE_NAMES + list(
    CATEGORICAL_FEATURES_WITH_VOCABULARY.keys()
)

dataframe_formation = dataframe['Formation'].unique().tolist()
dataframe_formation_to_encoded = {x: i for i, x in enumerate(dataframe_formation)}
dataframe_index_to_formation = {i: x for i, x in enumerate(dataframe_formation)}
dataframe['Formation'] = dataframe['Formation'].map(dataframe_formation_to_encoded)



win_cate = dataframe['Win'].unique().tolist()
win_to_encoded = {x: i for i, x in enumerate(win_cate)}
index_to_win = {i: x for i, x in enumerate(win_cate)} 
dataframe['Win'] = dataframe['Win'].map(win_to_encoded)

dataframe.dtypes

dataframe = dataframe.sample(frac=1, random_state=42)
dataframe

# # 10-11 ~ 19-20 시즌 - train
# train_dt = dataframe[dataframe['Season'] != '2020-2021']

# # 20-21 시즌 - test
# test_dt = dataframe[dataframe['Season'] == '2020-2021']

# 전체 데이터를 학습데이터로 해보기!
#####
def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):
    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
    plt.figure(figsize=(8, 16))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    
    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names)
        plt.yticks(tick_marks, target_names)
    
    if labels:
        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
            if normalize:
                plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                         horizontalalignment="center",
                         color="white" if cm[i, j] > thresh else "black")
            else:
                plt.text(j, i, "{:,}".format(cm[i, j]),
                         horizontalalignment="center",
                         color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()


# class GatedResidualNetwork(layers.Layer):
#     def __init__(self, units, dropout_rate):
#         super(GatedResidualNetwork, self).__init__()
#         self.units = units
#         self.elu_dense = layers.Dense(units, activation="elu")
#         self.linear_dense = layers.Dense(units)
#         self.dropout = layers.Dropout(dropout_rate)
#         self.gated_linear_unit = GatedLinearUnit(units)
#         self.layer_norm = layers.LayerNormalization()
#         self.project = layers.Dense(units)

#     def call(self, inputs):
#         x = self.elu_dense(inputs)
#         x = self.linear_dense(x)
#         x = self.dropout(x)
#         if inputs.shape[-1] != self.units:
#             inputs = self.project(inputs)
#         x = inputs + self.gated_linear_unit(x)
#         x = self.layer_norm(x)
#         return x    


# class VariableSelection(layers.Layer):
#     def __init__(self, num_features, units, dropout_rate):
#         super(VariableSelection, self).__init__()
#         self.grns = list()
#         # Create a GRN for each feature independently
#         for idx in range(num_features):
#             grn = GatedResidualNetwork(units, dropout_rate)
#             self.grns.append(grn)
#         # Create a GRN for the concatenation of all the features
#         self.grn_concat = GatedResidualNetwork(units, dropout_rate)
#         self.softmax = layers.Dense(units=num_features, activation="softmax")

#     def call(self, inputs):
#         v = layers.concatenate(inputs)
#         v = self.grn_concat(v)
#         v = tf.expand_dims(self.softmax(v), axis=-1)

#         x = []
#         for idx, input in enumerate(inputs):
#             x.append(self.grns[idx](input))
#         x = tf.stack(x, axis=1)

#         outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)
#         return outputs


train_dataframe = dataframe.sample(380)
train_data = train_dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].values.astype(np.float)

train_data_cate = train_dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team']].values

###test
test_dataframe = dataframe.sample(38)
test_data = test_dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].values.astype(np.float)

test_data_cate = test_dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team']].values


y_formation = train_dataframe['Formation'].values
y_style = train_dataframe['Style'].values
y_win = train_dataframe['Win'].values


y_test_formation = test_dataframe['Formation'].values
y_test_style = test_dataframe['Style'].values
y_test_win = test_dataframe['Win'].values

def create_model_inputs():
    inputs = {}
    for feature_name in FEATURE_NAMES:
        if feature_name in NUMERIC_FEATURE_NAMES + BINARY_FEATURE_NAMES:
            inputs[feature_name] = layers.Input(
                name=feature_name, shape=(), dtype=tf.float32
            )
        else:
            inputs[feature_name] = layers.Input(
                name=feature_name, shape=(), dtype=tf.string
            )
    return inputs

def encode_inputs(inputs, encoding_size):
    encoded_features = []
    for feature_name in inputs:
        if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:
            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]
            # Create a lookup to convert a string values to an integer indices.
            # Since we are not using a mask token nor expecting any out of vocabulary
            # (oov) token, we set mask_token to None and  num_oov_indices to 0.
            index = StringLookup(
                vocabulary=vocabulary, mask_token=None, num_oov_indices=0
            )
            # Convert the string input values into integer indices.
            value_index = index(inputs[feature_name])
            # Create an embedding layer with the specified dimensions
            embedding_ecoder = layers.Embedding(
                input_dim=len(vocabulary), output_dim=encoding_size
            )
            # Convert the index values to embedding representations.
            encoded_feature = embedding_ecoder(value_index)
        elif feature_name in NUMERIC_FEATURE_NAMES:
            encoded_feature = tf.expand_dims(inputs[feature_name], -1)
            encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)
            encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)
            encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)

        else:
            # Project the numeric feature to encoding_size using linear transformation.
            encoded_feature = tf.expand_dims(inputs[feature_name], -1)
            encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)
        encoded_features.append(encoded_feature)
    return encoded_features

def create_model(encoding_size):
  inputs = create_model_inputs()
  feature_list = encode_inputs(inputs, encoding_size)
  concat = layers.concatenate(feature_list)

  x_1_input = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(concat)
  x_1 = layers.BatchNormalization()(x_1_input)
  x_1 = layers.Dropout(dropout_rate)(x_1)
  x_1 = layers.ReLU()(x_1)
  x_1 = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(x_1) + x_1_input
  output_for = layers.Dense(31, activation='softmax', name='output_for')(x_1)

  x_2_input = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(concat)
  x_2 = layers.BatchNormalization()(x_2_input)
  x_2 = layers.Dropout(dropout_rate)(x_2)
  x_2 = layers.ReLU()(x_2)
  x_2 = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(x_2) + x_2_input
  output_style = layers.Dense(2, activation='softmax', name='output_style')(x_2)

  x_3_input = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(concat)
  x_3 = layers.BatchNormalization()(x_3_input)
  x_3 = layers.Dropout(dropout_rate)(x_3)
  x_3 = layers.ReLU()(x_3)
  x_3 = layers.Dense(42, kernel_regularizer=keras.regularizers.l2(0.001))(x_3) + x_3_input
  x_3 = layers.Dense(24, kernel_regularizer=keras.regularizers.l2(0.001))(x_3)
  x_3 = layers.BatchNormalization()(x_3)
  x_3 = layers.Dropout(dropout_rate)(x_3)
  x_3 = layers.ReLU()(x_3)
  x_3 = layers.Dense(12)(x_3)
  x_3 = layers.BatchNormalization()(x_3)
  x_3 = layers.Dropout(dropout_rate)(x_3)
  x_3 = layers.ReLU()(x_3)
  output_win = layers.Dense(3, activation='softmax', name='output_win')(x_3)

  model = keras.Model(inputs=inputs, outputs = [output_for, output_style, output_win])
  return model

learning_rate = 0.01
dropout_rate = 0.20
num_epochs = 100
encoding_size = 16

model = create_model(encoding_size=encoding_size)

model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), 
              loss= {'output_for': keras.losses.SparseCategoricalCrossentropy(), 
                      'output_win':keras.losses.SparseCategoricalCrossentropy(), 
                      'output_style':keras.losses.SparseCategoricalCrossentropy()},
              metrics =  {'output_for': [keras.metrics.SparseCategoricalAccuracy()],
                      'output_win':[keras.metrics.SparseCategoricalAccuracy()], 
                      'output_style':[keras.metrics.SparseCategoricalAccuracy()] }
              
              # {'output_for': [keras.losses.SparseCategoricalCrossentropy() ,keras.metrics.Precision(name='precision'),keras.metrics.Recall(name='recall')],
              #         'output_win':[keras.losses.SparseCategoricalCrossentropy(),keras.metrics.Precision(name='precision'),keras.metrics.Recall(name='recall')], 
              #         'output_style':[keras.losses.SparseCategoricalCrossentropy() ,keras.metrics.Precision(name='precision'),keras.metrics.Recall(name='recall')]}
)

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience= 15, restore_best_weights=True)

history = model.fit(x={
    'FW0': train_data[:, 0:1],
    'FW0B':train_data[:, 1:2],
    "FW1" :train_data[:, 2:3],
    'AMF0':train_data[:, 3:4],
    'AMF0B':train_data[:, 4:5],
    'AMF1':train_data[:, 5:6],
    'AMF1B':train_data[:, 6:7],
    'Wing0':train_data[:, 7:8],
    'Wing0B':train_data[:, 8:9],
    'Wing1':train_data[:, 9:10],
    'Wing1B':train_data[:, 10:11],
    'CMF0':train_data[:, 11:12],
    'CMF0B':train_data[:, 12:13],
    'CMF0C':train_data[:, 13:14],
    'CMF1':train_data[:, 14:15],
    'CMF1B':train_data[:, 15:16],
    'DMF0':train_data[:, 16:17],
    'DMF1':train_data[:, 17:18],
    'DMF1B':train_data[:, 18:19],
    'WB0':train_data[:, 19:20],
    'WB0B':train_data[:, 20:21],
    'WB1':train_data[:, 21:22],
    'WB1B':train_data[:, 22:23],
    'CB0':train_data[:, 23:24],
    'CB0B':train_data[:, 24:25],
    'CB1':train_data[:, 25:26],
    'CB1B':train_data[:, 26:27],
    'GK0':train_data[:, 27:28],
    'GK1':train_data[:, 28:29],
    'Ball_pos':train_data[:, 29:30],

    'Opp_Level':train_data_cate[:, 0:1],
    'Season':train_data_cate[:, 1:2],
    'match_oder':train_data_cate[:, 2:3],
    'oppense_team':train_data_cate[:, 3:4],
    }, 
    y = {'output_for': y_formation, 
         'output_style': y_style,
         'output_win':y_win}, 
         epochs=num_epochs, 
         validation_split=0.05 , 
         callbacks=[early_stop])

model.evaluate(x={
    'FW0': test_data[:, 0:1],
    'FW0B':test_data[:, 1:2],
    "FW1" :test_data[:, 2:3],
    'AMF0':test_data[:, 3:4],
    'AMF0B':test_data[:, 4:5],
    'AMF1':test_data[:, 5:6],
    'AMF1B':test_data[:, 6:7],
    'Wing0':test_data[:, 7:8],
    'Wing0B':test_data[:, 8:9],
    'Wing1':test_data[:, 9:10],
    'Wing1B':test_data[:, 10:11],
    'CMF0':test_data[:, 11:12],
    'CMF0B':test_data[:, 12:13],
    'CMF0C':test_data[:, 13:14],
    'CMF1':test_data[:, 14:15],
    'CMF1B':test_data[:, 15:16],
    'DMF0':test_data[:, 16:17],
    'DMF1':test_data[:, 17:18],
    'DMF1B':test_data[:, 18:19],
    'WB0':test_data[:, 19:20],
    'WB0B':test_data[:, 20:21],
    'WB1':test_data[:, 21:22],
    'WB1B':test_data[:, 22:23],
    'CB0':test_data[:, 23:24],
    'CB0B':test_data[:, 24:25],
    'CB1':test_data[:, 25:26],
    'CB1B':test_data[:, 26:27],
    'GK0':test_data[:, 27:28],
    'GK1':test_data[:, 28:29],
    'Ball_pos':test_data[:, 29:30],

    'Opp_Level':test_data_cate[:, 0:1],
    'Season':test_data_cate[:, 1:2],
    'match_oder':test_data_cate[:, 2:3],
    'oppense_team':test_data_cate[:, 3:4],
    }, 
    y = {'output_for': y_test_formation, 
         'output_style': y_test_style,
         'output_win':y_test_win})

dataframe

test_dt = dataframe[dataframe['Season'] == '2020-2021']

###test
#test_dataframe = dataframe.sample(38)
test_data = test_dt[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].values.astype(np.float)

test_data_cate = test_dt[['Opp_Level', 'Season','match_oder', 'oppense_team']].values

y_test_formation = test_dt['Formation'].values
y_test_style = test_dt['Style'].values
y_test_win = test_dt['Win'].values





#### 데이터 검증방법, 여기서부터 시작하기!

from sklearn.model_selection import train_test_split # holdout - validation
from sklearn.model_selection import KFold # k-flod 크로스 벨리데이션 
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import LeavePOut
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import StratifiedKFold

dataframe = dataframe.sample(frac=1, random_state=None,)
dataframe.head()

#### hold out 방법
dataframe1 = dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].astype(np.float)

dataframe2 = dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team', 'Formation', 'Style', 'Win']]
df_cat = pd.concat([dataframe1, dataframe2], axis=1)

x1 = df_cat.drop(['Formation', 'Style', 'Win'], axis=1).values
y1 = df_cat[['Formation', 'Style', 'Win']].values

# Holdout Validation Approach - Train and Test Set Split

hold_no = 1
acc_per_hold = []
loss_per_hold = []

cfmean_for = []
cfmean_style = []
cfmean_win = []
accmean_for = []
accmean_style = []
accmean_win = []
precmean_for = []
precmean_style = []
precmean_win = []
recmean_for = []
recmean_style = []
recmean_win = []



early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience= 15, restore_best_weights=True)

model = create_model(encoding_size=encoding_size) 

model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), 
            loss= {'output_for': keras.losses.SparseCategoricalCrossentropy(), 
                    'output_win':keras.losses.SparseCategoricalCrossentropy(), 
                    'output_style':keras.losses.SparseCategoricalCrossentropy()},
            metrics =  {'output_for': [keras.metrics.SparseCategoricalAccuracy()],
                    'output_win':[keras.metrics.SparseCategoricalAccuracy()], 
                    'output_style':[keras.metrics.SparseCategoricalAccuracy()] })


for i in range(5):

  X_train, X_test, Y_train, Y_test = train_test_split(x1, y1, test_size=0.1)
                                                      #randomstate = 41)

  X_train_num = X_train[:, :30].astype(np.float)
  X_train_obj = X_train[:, 30:]

  X_test_num = X_test[:, :30].astype(np.float)
  X_test_obj = X_test[:, 30:]
                



  print('------------------------------------------------------------------------')
  print(f'Training for hold {hold_no} ...')

  history = model.fit(x={
    'FW0': X_train_num[:, 0:1],
    'FW0B':X_train_num[:, 1:2],
    "FW1" :X_train_num[:, 2:3],
    'AMF0':X_train_num[:, 3:4],
    'AMF0B':X_train_num[:, 4:5],
    'AMF1':X_train_num[:, 5:6],
    'AMF1B':X_train_num[:, 6:7],
    'Wing0':X_train_num[:, 7:8],
    'Wing0B':X_train_num[:, 8:9],
    'Wing1':X_train_num[:, 9:10],
    'Wing1B':X_train_num[:, 10:11],
    'CMF0':X_train_num[:, 11:12],
    'CMF0B':X_train_num[:, 12:13],
    'CMF0C':X_train_num[:, 13:14],
    'CMF1':X_train_num[:, 14:15],
    'CMF1B':X_train_num[:, 15:16],
    'DMF0':X_train_num[:, 16:17],
    'DMF1':X_train_num[:, 17:18],
    'DMF1B':X_train_num[:, 18:19],
    'WB0':X_train_num[:, 19:20],
    'WB0B':X_train_num[:, 20:21],
    'WB1':X_train_num[:, 21:22],
    'WB1B':X_train_num[:, 22:23],
    'CB0':X_train_num[:, 23:24],
    'CB0B':X_train_num[:, 24:25],
    'CB1':X_train_num[:, 25:26],
    'CB1B':X_train_num[:, 26:27],
    'GK0':X_train_num[:, 27:28],
    'GK1':X_train_num[:, 28:29],
    'Ball_pos':X_train_num[:, 29:30],

    'Opp_Level':X_train_obj[:, 0:1],
    'Season':X_train_obj[:, 1:2],
    'match_oder':X_train_obj[:, 2:3],
    'oppense_team':X_train_obj[:, 3:4],
    }, 
    y = {'output_for': Y_train[:, 0], 
         'output_style': Y_train[:, 1],
         'output_win':Y_train[:, 2]}, 
         
         epochs=num_epochs, 
         validation_split=0.01 , 
         callbacks=[early_stop])
  
  # Generate generalization metrics
  scores_hold = model.evaluate(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    }, 
    y = {'output_for': Y_test[:, 0], 
         'output_style': Y_test[:, 1],
         'output_win':Y_test[:, 2]})
  

  print(f'Score for hold {hold_no}: {model.metrics_names[0]} of {scores_hold[0]}; {model.metrics_names[4]} of {scores_hold[4]*100}%; {model.metrics_names[5]} of {scores_hold[5]*100}%\
  ; {model.metrics_names[6]} of {scores_hold[6]*100}%')

  acc_per_hold.append([scores_hold[4] * 100, scores_hold[5] * 100, scores_hold[6] * 100])
  loss_per_hold.append(scores_hold[0])

  # Increase fold number
  hold_no = hold_no + 1

  y_pred = model.predict(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    })
  
  pred_for = []
  pred_style = []
  pred_win = []

  for i in y_pred[0:1][0]:
    pred_for.append(argmax(i))

  for i in y_pred[1:2][0]:
    pred_style.append(argmax(i))

  for i in y_pred[2:3][0]:
    pred_win.append(argmax(i))

  
  accmean_for.append(accuracy_score(Y_test[:, 0], pred_for))
  accmean_style.append(accuracy_score(Y_test[:, 1], pred_style))
  accmean_win.append(accuracy_score(Y_test[:, 2], pred_win))

  precmean_for.append(precision_score(Y_test[:, 0], pred_for, average='micro'))
  precmean_style.append(precision_score(Y_test[:, 1], pred_style, average='binary'))
  precmean_win.append(precision_score(Y_test[:, 2], pred_win, average='micro'))

  recmean_for.append(recall_score(Y_test[:, 0], pred_for, average='micro'))
  recmean_style.append(recall_score(Y_test[:, 1], pred_style, average='binary'))
  recmean_win.append(recall_score(Y_test[:, 2], pred_for, average='micro'))

  print(classification_report(Y_test[:, 0], pred_for, ))
  print(classification_report(Y_test[:, 1], pred_style, ))
  print(classification_report(Y_test[:, 2], pred_win, ))

  cfmean_for.append(confusion_matrix(Y_test[:, 0], pred_for))
  cfmean_style.append(confusion_matrix(Y_test[:, 1], pred_style))
  cfmean_win.append(confusion_matrix(Y_test[:, 2], pred_win))

  plot_confusion_matrix(confusion_matrix(Y_test[:, 0], pred_for), normalize=True, target_names=pd.Series(Y_test[:, 0]).unique().tolist() )
  #confusion_matrix(Y_test[:, 0], pred_for)


acc_for = np.mean(accmean_for, axis=0)
acc_style = np.mean(accmean_style, axis=0)
acc_win = np.mean(accmean_win, axis=0)

pre_for = np.mean(precmean_for, axis=0)
pre_style = np.mean(precmean_style, axis=0)
pre_win = np.mean(precmean_win, axis=0)

#cm_for = np.mean(cfmean_for, axis=0)
cm_style = np.mean(cfmean_style, axis=0)
cm_win = np.mean(cfmean_win, axis=0)

re_for = np.mean(recmean_for, axis=0)
re_style = np.mean(recmean_style, axis=0)
re_win = np.mean(recmean_win, axis=0)

print('\n')
print("Averages")
print("Accuracy_formation: " + str(acc_for))
print("Accuracy_style: " + str(acc_style))
print("Accuracy_win: " + str(acc_win))

print("Precision_formation: " + str(pre_for))
print("Precision_style: " + str(pre_style))
print("Precision_win: " + str(pre_win))

print("Recall_formation: " + str(re_for))
print("Recall_style: " + str(re_style))
print("Recall_win: " + str(re_win))



print('Style Confusion Matrix\n')
print(cm_style)

plot_confusion_matrix(cm_style, normalize=True, target_names= ['Offensive', 'Defensive'] )

print('Win Confusion Matrix\n')
print(cm_win)

plot_confusion_matrix(cm_win, normalize=True, target_names= ['Win', 'Draw', 'Lose'] )









# K-fold cross validation 
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score

dataframe1 = dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].astype(np.float)

dataframe2 = dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team', 'Formation', 'Style', 'Win']]
df_cat = pd.concat([dataframe1, dataframe2], axis=1)

x1 = df_cat.drop(['Formation', 'Style', 'Win'], axis=1).values
y1 = df_cat[['Formation', 'Style', 'Win']].values

model = create_model(encoding_size=encoding_size) 

model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), 
            loss= {'output_for': keras.losses.SparseCategoricalCrossentropy(), 
                    'output_win':keras.losses.SparseCategoricalCrossentropy(), 
                    'output_style':keras.losses.SparseCategoricalCrossentropy()},
            metrics =  {'output_for': [keras.metrics.SparseCategoricalAccuracy()],
                    'output_win':[keras.metrics.SparseCategoricalAccuracy()], 
                    'output_style':[keras.metrics.SparseCategoricalAccuracy()] })

num_folds = 5
kfold = KFold(n_splits=num_folds, shuffle=True)
fold_no = 1
acc_per_fold = []
loss_per_fold = []

cfmean_for = []
cfmean_style = []
cfmean_win = []
accmean_for = []
accmean_style = []
accmean_win = []
precmean_for = []
precmean_style = []
precmean_win = []
recmean_for = []
recmean_style = []
recmean_win = []



for train, test in kfold.split(x1, y1):
  X_train = x1[train]
  X_test = x1[test]

  X_train_num = X_train[:, :30].astype(np.float)
  X_train_obj = X_train[:, 30:]

  X_test_num = X_test[:, :30].astype(np.float)
  X_test_obj = X_test[:, 30:]

  Y_train = y1[train]
  Y_test = y1[test]



  # Generate a print
  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history = model.fit(x={
    'FW0': X_train_num[:, 0:1],
    'FW0B':X_train_num[:, 1:2],
    "FW1" :X_train_num[:, 2:3],
    'AMF0':X_train_num[:, 3:4],
    'AMF0B':X_train_num[:, 4:5],
    'AMF1':X_train_num[:, 5:6],
    'AMF1B':X_train_num[:, 6:7],
    'Wing0':X_train_num[:, 7:8],
    'Wing0B':X_train_num[:, 8:9],
    'Wing1':X_train_num[:, 9:10],
    'Wing1B':X_train_num[:, 10:11],
    'CMF0':X_train_num[:, 11:12],
    'CMF0B':X_train_num[:, 12:13],
    'CMF0C':X_train_num[:, 13:14],
    'CMF1':X_train_num[:, 14:15],
    'CMF1B':X_train_num[:, 15:16],
    'DMF0':X_train_num[:, 16:17],
    'DMF1':X_train_num[:, 17:18],
    'DMF1B':X_train_num[:, 18:19],
    'WB0':X_train_num[:, 19:20],
    'WB0B':X_train_num[:, 20:21],
    'WB1':X_train_num[:, 21:22],
    'WB1B':X_train_num[:, 22:23],
    'CB0':X_train_num[:, 23:24],
    'CB0B':X_train_num[:, 24:25],
    'CB1':X_train_num[:, 25:26],
    'CB1B':X_train_num[:, 26:27],
    'GK0':X_train_num[:, 27:28],
    'GK1':X_train_num[:, 28:29],
    'Ball_pos':X_train_num[:, 29:30],

    'Opp_Level':X_train_obj[:, 0:1],
    'Season':X_train_obj[:, 1:2],
    'match_oder':X_train_obj[:, 2:3],
    'oppense_team':X_train_obj[:, 3:4],
    }, 
    y = {'output_for': Y_train[:, 0], 
         'output_style': Y_train[:, 1],
         'output_win':Y_train[:, 2]}, 
         
         epochs=num_epochs, 
         validation_split=0.01 , 
         callbacks=[early_stop])
  

# Generate generalization metrics
  scores = model.evaluate(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    }, 
    y = {'output_for': Y_test[:, 0], 
         'output_style': Y_test[:, 1],
         'output_win':Y_test[:, 2]})
  

  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[4]} of {scores[4]*100}%; {model.metrics_names[5]} of {scores[5]*100}%\
  ; {model.metrics_names[6]} of {scores[6]*100}%')

  acc_per_fold.append([scores[4] * 100, scores[5] * 100, scores[6] * 100])
  loss_per_fold.append(scores[0])

  # Increase fold number
  fold_no = fold_no + 1

  y_pred = model.predict(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    })
  
  pred_for = []
  pred_style = []
  pred_win = []

  for i in y_pred[0:1][0]:
    pred_for.append(argmax(i))

  for i in y_pred[1:2][0]:
    pred_style.append(argmax(i))

  for i in y_pred[2:3][0]:
    pred_win.append(argmax(i))

  
  accmean_for.append(accuracy_score(Y_test[:, 0], pred_for))
  accmean_style.append(accuracy_score(Y_test[:, 1], pred_style))
  accmean_win.append(accuracy_score(Y_test[:, 2], pred_win))

  precmean_for.append(precision_score(Y_test[:, 0], pred_for, average='micro'))
  precmean_style.append(precision_score(Y_test[:, 1], pred_style, average='binary'))
  precmean_win.append(precision_score(Y_test[:, 2], pred_win, average='micro'))

  recmean_for.append(recall_score(Y_test[:, 0], pred_for, average='micro'))
  recmean_style.append(recall_score(Y_test[:, 1], pred_style, average='binary'))
  recmean_win.append(recall_score(Y_test[:, 2], pred_for, average='micro'))

  print(classification_report(Y_test[:, 0], pred_for, ))
  print(classification_report(Y_test[:, 1], pred_style, ))
  print(classification_report(Y_test[:, 2], pred_win, ))

  cfmean_for.append(confusion_matrix(Y_test[:, 0], pred_for))
  cfmean_style.append(confusion_matrix(Y_test[:, 1], pred_style))
  cfmean_win.append(confusion_matrix(Y_test[:, 2], pred_win))

  plot_confusion_matrix(confusion_matrix(Y_test[:, 0], pred_for), normalize=True, target_names=pd.Series(Y_test[:, 0]).unique().tolist() )
  #confusion_matrix(Y_test[:, 0], pred_for)


acc_for = np.mean(accmean_for, axis=0)
acc_style = np.mean(accmean_style, axis=0)
acc_win = np.mean(accmean_win, axis=0)

pre_for = np.mean(precmean_for, axis=0)
pre_style = np.mean(precmean_style, axis=0)
pre_win = np.mean(precmean_win, axis=0)

#cm_for = np.mean(cfmean_for, axis=0)
cm_style = np.mean(cfmean_style, axis=0)
cm_win = np.mean(cfmean_win, axis=0)

re_for = np.mean(recmean_for, axis=0)
re_style = np.mean(recmean_style, axis=0)
re_win = np.mean(recmean_win, axis=0)

print('\n')
print("Averages")
print("Accuracy_formation: " + str(acc_for))
print("Accuracy_style: " + str(acc_style))
print("Accuracy_win: " + str(acc_win))

print("Precision_formation: " + str(pre_for))
print("Precision_style: " + str(pre_style))
print("Precision_win: " + str(pre_win))

print("Recall_formation: " + str(re_for))
print("Recall_style: " + str(re_style))
print("Recall_win: " + str(re_win))



print('Style Confusion Matrix\n')
print(cm_style)

plot_confusion_matrix(cm_style, normalize=True, target_names= ['Offensive', 'Defensive'] )

print('Win Confusion Matrix\n')
print(cm_win)

plot_confusion_matrix(cm_win, normalize=True, target_names= ['Win', 'Draw', 'Lose'] )

model.metrics



#### Stratified K-fold Cross-Validation

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import StratifiedKFold


dataframe1 = dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].astype(np.float)

dataframe2 = dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team', 'Formation', 'Style', 'Win']]
df_cat = pd.concat([dataframe1, dataframe2], axis=1)

x1 = df_cat.drop(['Formation', 'Style', 'Win'], axis=1).values
y1 = df_cat[['Formation', 'Style', 'Win']].values

model = create_model(encoding_size=encoding_size) 

model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), 
            loss= {'output_for': keras.losses.SparseCategoricalCrossentropy(), 
                    'output_win':keras.losses.SparseCategoricalCrossentropy(), 
                    'output_style':keras.losses.SparseCategoricalCrossentropy()},
            metrics =  {'output_for': [keras.metrics.SparseCategoricalAccuracy()],
                    'output_win':[keras.metrics.SparseCategoricalAccuracy()], 
                    'output_style':[keras.metrics.SparseCategoricalAccuracy()] })


num_folds = 5
skfold = StratifiedKFold(n_splits=num_folds, shuffle=True)
fold_no = 1
acc_per_skfold = []
loss_per_skfold = []

cfmean_for = []
cfmean_style = []
cfmean_win = []
accmean_for = []
accmean_style = []
accmean_win = []
precmean_for = []
precmean_style = []
precmean_win = []
recmean_for = []
recmean_style = []
recmean_win = []



for train, test in skfold.split(x1, y1[:, 1]):
  X_train = x1[train]
  X_test = x1[test]

  X_train_num = X_train[:, :30].astype(np.float)
  X_train_obj = X_train[:, 30:]

  X_test_num = X_test[:, :30].astype(np.float)
  X_test_obj = X_test[:, 30:]

  Y_train = y1[train]
  Y_test = y1[test]



  # Generate a print
  print('------------------------------------------------------------------------')
  print(f'Training for fold {fold_no} ...')

  history = model.fit(x={
    'FW0': X_train_num[:, 0:1],
    'FW0B':X_train_num[:, 1:2],
    "FW1" :X_train_num[:, 2:3],
    'AMF0':X_train_num[:, 3:4],
    'AMF0B':X_train_num[:, 4:5],
    'AMF1':X_train_num[:, 5:6],
    'AMF1B':X_train_num[:, 6:7],
    'Wing0':X_train_num[:, 7:8],
    'Wing0B':X_train_num[:, 8:9],
    'Wing1':X_train_num[:, 9:10],
    'Wing1B':X_train_num[:, 10:11],
    'CMF0':X_train_num[:, 11:12],
    'CMF0B':X_train_num[:, 12:13],
    'CMF0C':X_train_num[:, 13:14],
    'CMF1':X_train_num[:, 14:15],
    'CMF1B':X_train_num[:, 15:16],
    'DMF0':X_train_num[:, 16:17],
    'DMF1':X_train_num[:, 17:18],
    'DMF1B':X_train_num[:, 18:19],
    'WB0':X_train_num[:, 19:20],
    'WB0B':X_train_num[:, 20:21],
    'WB1':X_train_num[:, 21:22],
    'WB1B':X_train_num[:, 22:23],
    'CB0':X_train_num[:, 23:24],
    'CB0B':X_train_num[:, 24:25],
    'CB1':X_train_num[:, 25:26],
    'CB1B':X_train_num[:, 26:27],
    'GK0':X_train_num[:, 27:28],
    'GK1':X_train_num[:, 28:29],
    'Ball_pos':X_train_num[:, 29:30],

    'Opp_Level':X_train_obj[:, 0:1],
    'Season':X_train_obj[:, 1:2],
    'match_oder':X_train_obj[:, 2:3],
    'oppense_team':X_train_obj[:, 3:4],
    }, 
    y = {'output_for': Y_train[:, 0], 
         'output_style': Y_train[:, 1],
         'output_win':Y_train[:, 2]}, 
         
         epochs=num_epochs, 
         validation_split=0.01 , 
         callbacks=[early_stop])
  

# Generate generalization metrics
  scores = model.evaluate(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    }, 
    y = {'output_for': Y_test[:, 0], 
         'output_style': Y_test[:, 1],
         'output_win':Y_test[:, 2]})
  

  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[4]} of {scores[4]*100}%; {model.metrics_names[5]} of {scores[5]*100}%\
  ; {model.metrics_names[6]} of {scores[6]*100}%')

  acc_per_skfold.append([scores[4] * 100, scores[5] * 100, scores[6] * 100])
  loss_per_skfold.append(scores[0])

  # Increase fold number
  fold_no = fold_no + 1

  y_pred = model.predict(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    })
  
  pred_for = []
  pred_style = []
  pred_win = []

  for i in y_pred[0:1][0]:
    pred_for.append(argmax(i))

  for i in y_pred[1:2][0]:
    pred_style.append(argmax(i))

  for i in y_pred[2:3][0]:
    pred_win.append(argmax(i))

  
  accmean_for.append(accuracy_score(Y_test[:, 0], pred_for))
  accmean_style.append(accuracy_score(Y_test[:, 1], pred_style))
  accmean_win.append(accuracy_score(Y_test[:, 2], pred_win))

  precmean_for.append(precision_score(Y_test[:, 0], pred_for, average='micro'))
  precmean_style.append(precision_score(Y_test[:, 1], pred_style, average='binary'))
  precmean_win.append(precision_score(Y_test[:, 2], pred_win, average='micro'))

  recmean_for.append(recall_score(Y_test[:, 0], pred_for, average='micro'))
  recmean_style.append(recall_score(Y_test[:, 1], pred_style, average='binary'))
  recmean_win.append(recall_score(Y_test[:, 2], pred_for, average='micro'))

  print(classification_report(Y_test[:, 0], pred_for, ))
  print(classification_report(Y_test[:, 1], pred_style, ))
  print(classification_report(Y_test[:, 2], pred_win, ))

  cfmean_for.append(confusion_matrix(Y_test[:, 0], pred_for))
  cfmean_style.append(confusion_matrix(Y_test[:, 1], pred_style))
  cfmean_win.append(confusion_matrix(Y_test[:, 2], pred_win))

  plot_confusion_matrix(confusion_matrix(Y_test[:, 0], pred_for), normalize=True, target_names=pd.Series(Y_test[:, 0]).unique().tolist() )
  #confusion_matrix(Y_test[:, 0], pred_for)


acc_for = np.mean(accmean_for, axis=0)
acc_style = np.mean(accmean_style, axis=0)
acc_win = np.mean(accmean_win, axis=0)

pre_for = np.mean(precmean_for, axis=0)
pre_style = np.mean(precmean_style, axis=0)
pre_win = np.mean(precmean_win, axis=0)

#cm_for = np.mean(cfmean_for, axis=0)
cm_style = np.mean(cfmean_style, axis=0)
cm_win = np.mean(cfmean_win, axis=0)

re_for = np.mean(recmean_for, axis=0)
re_style = np.mean(recmean_style, axis=0)
re_win = np.mean(recmean_win, axis=0)

print('\n')
print("Averages")
print("Accuracy_formation: " + str(acc_for))
print("Accuracy_style: " + str(acc_style))
print("Accuracy_win: " + str(acc_win))

print("Precision_formation: " + str(pre_for))
print("Precision_style: " + str(pre_style))
print("Precision_win: " + str(pre_win))

print("Recall_formation: " + str(re_for))
print("Recall_style: " + str(re_style))
print("Recall_win: " + str(re_win))



print('Style Confusion Matrix\n')
print(cm_style)

plot_confusion_matrix(cm_style, normalize=True, target_names= ['Offensive', 'Defensive'] )

print('Win Confusion Matrix\n')
print(cm_win)

plot_confusion_matrix(cm_win, normalize=True, target_names= ['Win', 'Draw', 'Lose'] )

### Repeated Random Test-Train Splits



from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import StratifiedKFold

cfmean_for = []
cfmean_style = []
cfmean_win = []
accmean_for = []
accmean_style = []
accmean_win = []
precmean_for = []
precmean_style = []
precmean_win = []
recmean_for = []
recmean_style = []
recmean_win = []



dataframe1 = dataframe[["FW0", "FW0B", "FW1" ,'AMF0', 'AMF0B', 'AMF1', 'AMF1B',
       'Wing0', 'Wing0B', 'Wing1', 'Wing1B', 'CMF0', 'CMF0B', 'CMF0C', 'CMF1',
       'CMF1B', 'DMF0', 'DMF1', 'DMF1B', 'WB0', 'WB0B', 'WB1', 'WB1B', 'CB0',
       'CB0B', 'CB1', 'CB1B', 'GK0', 'GK1', 'Ball_pos']].astype(np.float)

dataframe2 = dataframe[['Opp_Level', 'Season','match_oder', 'oppense_team', 'Formation', 'Style', 'Win']]
df_cat = pd.concat([dataframe1, dataframe2], axis=1)

x1 = df_cat.drop(['Formation', 'Style', 'Win'], axis=1).values
y1 = df_cat[['Formation', 'Style', 'Win']].values

model = create_model(encoding_size=encoding_size) 

model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), 
            loss= {'output_for': keras.losses.SparseCategoricalCrossentropy(), 
                    'output_win':keras.losses.SparseCategoricalCrossentropy(), 
                    'output_style':keras.losses.SparseCategoricalCrossentropy()},
            metrics =  {'output_for': [keras.metrics.SparseCategoricalAccuracy()],
                    'output_win':[keras.metrics.SparseCategoricalAccuracy()], 
                    'output_style':[keras.metrics.SparseCategoricalAccuracy()] })


num_folds = 5
shuffle_split = ShuffleSplit(n_splits=5, test_size=0.20, random_state=100)
shfold_no = 1
acc_per_shfold = []
loss_per_shfold = []

for train, test in shuffle_split.split(x1, y1):
  X_train = x1[train]
  X_test = x1[test]

  X_train_num = X_train[:, :30].astype(np.float)
  X_train_obj = X_train[:, 30:]

  X_test_num = X_test[:, :30].astype(np.float)
  X_test_obj = X_test[:, 30:]

  Y_train = y1[train]
  Y_test = y1[test]



  # Generate a print
  print('------------------------------------------------------------------------')
  print(f'Training for fold {shfold_no} ...')

  history = model.fit(x={
    'FW0': X_train_num[:, 0:1],
    'FW0B':X_train_num[:, 1:2],
    "FW1" :X_train_num[:, 2:3],
    'AMF0':X_train_num[:, 3:4],
    'AMF0B':X_train_num[:, 4:5],
    'AMF1':X_train_num[:, 5:6],
    'AMF1B':X_train_num[:, 6:7],
    'Wing0':X_train_num[:, 7:8],
    'Wing0B':X_train_num[:, 8:9],
    'Wing1':X_train_num[:, 9:10],
    'Wing1B':X_train_num[:, 10:11],
    'CMF0':X_train_num[:, 11:12],
    'CMF0B':X_train_num[:, 12:13],
    'CMF0C':X_train_num[:, 13:14],
    'CMF1':X_train_num[:, 14:15],
    'CMF1B':X_train_num[:, 15:16],
    'DMF0':X_train_num[:, 16:17],
    'DMF1':X_train_num[:, 17:18],
    'DMF1B':X_train_num[:, 18:19],
    'WB0':X_train_num[:, 19:20],
    'WB0B':X_train_num[:, 20:21],
    'WB1':X_train_num[:, 21:22],
    'WB1B':X_train_num[:, 22:23],
    'CB0':X_train_num[:, 23:24],
    'CB0B':X_train_num[:, 24:25],
    'CB1':X_train_num[:, 25:26],
    'CB1B':X_train_num[:, 26:27],
    'GK0':X_train_num[:, 27:28],
    'GK1':X_train_num[:, 28:29],
    'Ball_pos':X_train_num[:, 29:30],

    'Opp_Level':X_train_obj[:, 0:1],
    'Season':X_train_obj[:, 1:2],
    'match_oder':X_train_obj[:, 2:3],
    'oppense_team':X_train_obj[:, 3:4],
    }, 
    y = {'output_for': Y_train[:, 0], 
         'output_style': Y_train[:, 1],
         'output_win':Y_train[:, 2]}, 
         
         epochs=num_epochs, 
         validation_split=0.01 , 
         callbacks=[early_stop])
  

# Generate generalization metrics
  scores = model.evaluate(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    }, 
    y = {'output_for': Y_test[:, 0], 
         'output_style': Y_test[:, 1],
         'output_win':Y_test[:, 2]})
  

  print(f'Score for fold {shfold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[4]} of {scores[4]*100}%; {model.metrics_names[5]} of {scores[5]*100}%\
  ; {model.metrics_names[6]} of {scores[6]*100}%')

  acc_per_shfold.append([scores[4] * 100, scores[5] * 100, scores[6] * 100])
  loss_per_shfold.append(scores[0])

  # Increase fold number
  shfold_no = shfold_no + 1


  y_pred = model.predict(x={
    'FW0': X_test_num[:, 0:1],
    'FW0B':X_test_num[:, 1:2],
    "FW1" :X_test_num[:, 2:3],
    'AMF0':X_test_num[:, 3:4],
    'AMF0B':X_test_num[:, 4:5],
    'AMF1':X_test_num[:, 5:6],
    'AMF1B':X_test_num[:, 6:7],
    'Wing0':X_test_num[:, 7:8],
    'Wing0B':X_test_num[:, 8:9],
    'Wing1':X_test_num[:, 9:10],
    'Wing1B':X_test_num[:, 10:11],
    'CMF0':X_test_num[:, 11:12],
    'CMF0B':X_test_num[:, 12:13],
    'CMF0C':X_test_num[:, 13:14],
    'CMF1':X_test_num[:, 14:15],
    'CMF1B':X_test_num[:, 15:16],
    'DMF0':X_test_num[:, 16:17],
    'DMF1':X_test_num[:, 17:18],
    'DMF1B':X_test_num[:, 18:19],
    'WB0':X_test_num[:, 19:20],
    'WB0B':X_test_num[:, 20:21],
    'WB1':X_test_num[:, 21:22],
    'WB1B':X_test_num[:, 22:23],
    'CB0':X_test_num[:, 23:24],
    'CB0B':X_test_num[:, 24:25],
    'CB1':X_test_num[:, 25:26],
    'CB1B':X_test_num[:, 26:27],
    'GK0':X_test_num[:, 27:28],
    'GK1':X_test_num[:, 28:29],
    'Ball_pos':X_test_num[:, 29:30],

    'Opp_Level':X_test_obj[:, 0:1],
    'Season':X_test_obj[:, 1:2],
    'match_oder':X_test_obj[:, 2:3],
    'oppense_team':X_test_obj[:, 3:4],
    })
  
  pred_for = []
  pred_style = []
  pred_win = []

  for i in y_pred[0:1][0]:
    pred_for.append(argmax(i))

  for i in y_pred[1:2][0]:
    pred_style.append(argmax(i))

  for i in y_pred[2:3][0]:
    pred_win.append(argmax(i))

  
  accmean_for.append(accuracy_score(Y_test[:, 0], pred_for))
  accmean_style.append(accuracy_score(Y_test[:, 1], pred_style))
  accmean_win.append(accuracy_score(Y_test[:, 2], pred_win))

  precmean_for.append(precision_score(Y_test[:, 0], pred_for, average='micro'))
  precmean_style.append(precision_score(Y_test[:, 1], pred_style, average='binary'))
  precmean_win.append(precision_score(Y_test[:, 2], pred_win, average='micro'))

  recmean_for.append(recall_score(Y_test[:, 0], pred_for, average='micro'))
  recmean_style.append(recall_score(Y_test[:, 1], pred_style, average='binary'))
  recmean_win.append(recall_score(Y_test[:, 2], pred_for, average='micro'))

  print(classification_report(Y_test[:, 0], pred_for, ))
  print(classification_report(Y_test[:, 1], pred_style, ))
  print(classification_report(Y_test[:, 2], pred_win, ))

  cfmean_for.append(confusion_matrix(Y_test[:, 0], pred_for))
  cfmean_style.append(confusion_matrix(Y_test[:, 1], pred_style))
  cfmean_win.append(confusion_matrix(Y_test[:, 2], pred_win))

  plot_confusion_matrix(confusion_matrix(Y_test[:, 0], pred_for), normalize=True, target_names=pd.Series(Y_test[:, 0]).unique().tolist() )
  #confusion_matrix(Y_test[:, 0], pred_for)


acc_for = np.mean(accmean_for, axis=0)
acc_style = np.mean(accmean_style, axis=0)
acc_win = np.mean(accmean_win, axis=0)

pre_for = np.mean(precmean_for, axis=0)
pre_style = np.mean(precmean_style, axis=0)
pre_win = np.mean(precmean_win, axis=0)

#cm_for = np.mean(cfmean_for, axis=0)
cm_style = np.mean(cfmean_style, axis=0)
cm_win = np.mean(cfmean_win, axis=0)

re_for = np.mean(recmean_for, axis=0)
re_style = np.mean(recmean_style, axis=0)
re_win = np.mean(recmean_win, axis=0)

print('\n')
print("Averages")
print("Accuracy_formation: " + str(acc_for))
print("Accuracy_style: " + str(acc_style))
print("Accuracy_win: " + str(acc_win))

print("Precision_formation: " + str(pre_for))
print("Precision_style: " + str(pre_style))
print("Precision_win: " + str(pre_win))

print("Recall_formation: " + str(re_for))
print("Recall_style: " + str(re_style))
print("Recall_win: " + str(re_win))



print('Style Confusion Matrix\n')
print(cm_style)

plot_confusion_matrix(cm_style, normalize=True, target_names= ['Offensive', 'Defensive'] )

print('Win Confusion Matrix\n')
print(cm_win)

plot_confusion_matrix(cm_win, normalize=True, target_names= ['Win', 'Draw', 'Lose'] )



# # leave-one-out 방법

# from sklearn.model_selection import LeaveOneOut

# loo = LeaveOneOut()

# for train, test in loo.split(x1, y1):
#     print(train,test)

